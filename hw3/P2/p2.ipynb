{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict\n",
    "\n",
    "max_cluster = 20\n",
    "\n",
    "doc_word = np.load(\"data/science2k-doc-word.npy\")\n",
    "word_doc = np.load(\"data/science2k-word-doc.npy\")\n",
    "\n",
    "def read_text(filename):\n",
    "    li = []\n",
    "    f = open(filename, 'r')\n",
    "    for line in f:\n",
    "        li.append(line.strip())\n",
    "    f.close()\n",
    "    return li\n",
    "\n",
    "word_list = read_text(\"data/science2k-vocab.txt\")\n",
    "title_list = read_text(\"data/science2k-titles.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top10_col(col_list, centers, mean_vector, fname):\n",
    "    for i in range(len(centers)):\n",
    "        f = open(fname+'_c'+str(i+2)+'.txt', 'w')\n",
    "        f.write('number of clusters:'+str(i+2)+'\\n\\n')\n",
    "        for center in centers[i]:\n",
    "            temp = center - mean_vector\n",
    "            li = [(temp[i], i) for i in range(len(temp))]\n",
    "            ind = temp.argsort()[-10:][::-1]\n",
    "            for j in ind:\n",
    "                f.write(col_list[j]+'\\n')\n",
    "            f.write('\\n')\n",
    "        f.close()\n",
    "\n",
    "def print_top10_row(data, row_list, centers, predicts, fname):\n",
    "    numCluster = 2\n",
    "    for i in range(len(predicts)):\n",
    "        d = defaultdict(list)\n",
    "        for (j, p) in enumerate(predicts[i]):\n",
    "            d[p].append((np.linalg.norm(data[j] - centers[i][p]), j))\n",
    "        f = open(fname+'_c'+str(numCluster)+'.txt', 'w')\n",
    "        f.write('number of clusters:'+str(numCluster)+'\\n\\n')\n",
    "        numCluster += 1\n",
    "        for j in range(numCluster):\n",
    "            li = sorted(d[j])[:11]\n",
    "            for idx in li:\n",
    "                f.write(row_list[idx[1]]+'\\n')\n",
    "            f.write('\\n')\n",
    "        f.close()\n",
    "\n",
    "def train_kmeans(data):\n",
    "    centers = []\n",
    "    predicts = []\n",
    "    for numCluster in range(2, max_cluster + 1):\n",
    "        k = KMeans(n_clusters = numCluster, random_state = 42).fit(data)\n",
    "        centers.append(k.cluster_centers_)\n",
    "        predicts.append(k.predict(data))\n",
    "    mean_vector = np.mean(data, axis=0)\n",
    "    return centers, predicts, mean_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_centers, doc_predicts, doc_mean = train_kmeans(doc_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top10_row(doc_word, title_list, doc_centers, doc_predicts, 'doc_K-Mean_top_documents')\n",
    "print_top10_col(word_list, doc_centers, doc_mean, 'doc_K-Mean_top_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_centers, word_predicts, word_mean = train_kmeans(word_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top10_row(word_doc, word_list, word_centers, word_predicts, 'word_K-Mean_top_words')\n",
    "print_top10_col(title_list, word_centers, word_mean, 'word_K-Mean_top_documents')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
