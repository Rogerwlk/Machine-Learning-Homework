{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.linear_model import Lasso\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.cross_decomposition import PLSRegression\n",
    "# from sklearn.cross_decomposition import PLSCanonical\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 7077)\n",
      "(10000, 300)\n",
      "(10000, 102)\n",
      "(10000, 300)\n",
      "(10000, 1000)\n",
      "(10000, 2048)\n",
      "(2000, 7077)\n",
      "(2000, 300)\n",
      "(2000, 102)\n",
      "(2000, 300)\n",
      "(2000, 1000)\n",
      "(2000, 2048)\n"
     ]
    }
   ],
   "source": [
    "# d: description, t: tag, f: 1000 feature, fi: 2048 intermediate features, bow: bag of word, w2v: word 2 vector\n",
    "d_train_bow = np.load('preprocessing/bagOfWord_train_description.npy')\n",
    "d_train_w2v = np.load('preprocessing/word2vec_train_description.npy')\n",
    "t_train_bow = np.load('preprocessing/bagOfWord_train_tag.npy')\n",
    "t_train_w2v = np.load('preprocessing/word2vec_train_tag.npy')\n",
    "f_train = np.load('preprocessing/word2vec_train_1000feature.npy')\n",
    "fi_train = np.load('preprocessing/word2vec_train_2048feature.npy')\n",
    "\n",
    "print(d_train_bow.shape)\n",
    "print(d_train_w2v.shape)\n",
    "print(t_train_bow.shape)\n",
    "print(t_train_w2v.shape)\n",
    "print(f_train.shape)\n",
    "print(fi_train.shape)\n",
    "\n",
    "d_test_bow = np.load('preprocessing/bagOfWord_test_description.npy')\n",
    "d_test_w2v = np.load('preprocessing/word2vec_test_description.npy')\n",
    "t_test_bow = np.load('preprocessing/bagOfWord_test_tag.npy')\n",
    "t_test_w2v = np.load('preprocessing/word2vec_test_tag.npy')\n",
    "f_test = np.load('preprocessing/word2vec_test_1000feature.npy')\n",
    "fi_test = np.load('preprocessing/word2vec_test_2048feature.npy')\n",
    "\n",
    "print(d_test_bow.shape)\n",
    "print(d_test_w2v.shape)\n",
    "print(t_test_bow.shape)\n",
    "print(t_test_w2v.shape)\n",
    "print(f_test.shape)\n",
    "print(fi_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3150)\n",
      "(10000, 7077)\n"
     ]
    }
   ],
   "source": [
    "trainX = np.concatenate((t_train_bow, f_train, fi_train), axis=1)\n",
    "print(trainX.shape)\n",
    "trainY = d_train_bow\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3150)\n"
     ]
    }
   ],
   "source": [
    "testX = np.concatenate((t_test_bow, f_test, fi_test), axis=1)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_prediction(testY, filename):\n",
    "    distance = cdist(d_test_bow, testY, 'euclidean')\n",
    "    f = open(filename, \"w\")\n",
    "    f.write(\"Descritpion_ID,Top_20_Image_IDs\\n\")\n",
    "    for i in range(2000):\n",
    "        test_dist_idx = list(np.argsort(distance[i]))\n",
    "        top_20 = test_dist_idx[:20]\n",
    "        row = [\"%d.jpg\" % i for i in top_20]\n",
    "        f.write(\"%d.txt,%s\\n\" % (i, \" \".join(row)))\n",
    "    f.close()\n",
    "    print(\"Output written!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 256)\n",
      "(2000, 256)\n"
     ]
    }
   ],
   "source": [
    "##SVD\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=256, n_iter=7, random_state=42)\n",
    "trainY=svd.fit_transform(trainY)\n",
    "print(trainY.shape)\n",
    "\n",
    "d_test_bow=svd.fit_transform(d_test_bow)\n",
    "print(d_test_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nerual Network\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation=tf.nn.sigmoid),\n",
    "    #keras.layers.Dense(3105, activation=tf.nn.sigmoid),\n",
    "    keras.layers.Dense(256)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='sgd', \n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 2s 200us/step - loss: 0.5513\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.4845\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.4670\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.4552\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 2s 184us/step - loss: 0.4464\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.4394\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.4336\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.4287\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.4243\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 2s 184us/step - loss: 0.4205\n",
      "Output written!\n"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=10)\n",
    "testY=model.predict(testX)\n",
    "output_prediction(testY, 'NN_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testY = LinearRegression(n_jobs=-1).fit(trainX, trainY).predict(testX)\n",
    "# output_prediction(testY, 'linear_regression_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testY = Lasso(n_jobs=-1).fit(trainX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
