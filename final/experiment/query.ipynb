{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, glob, nltk\n",
    "from collections import Counter\n",
    "from math import log\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable\n",
    "idx_table = {}\n",
    "docu_table = {}\n",
    "weight_table = {}\n",
    "stop_words = set()\n",
    "f = open('stops.txt', 'r')\n",
    "for line in f:\n",
    "    stop_words.add(line.strip())\n",
    "f.close()\n",
    "retrieval_model = 'lm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df(term):\n",
    "    return len(idx_table[term])\n",
    "\n",
    "def idf(term):\n",
    "    return log(len(docu_table) / df(term), 10)\n",
    "\n",
    "def cosineSimilarity(query, docno, query_counter):\n",
    "    c_dividend = 0 # dividend in formula\n",
    "    c_divisor_d = 0 # document divisor in formula\n",
    "    c_divisor_w = 0 # query divisor in formula\n",
    "    for term in query:\n",
    "        w = query_counter[term] * idf(term)\n",
    "        d = docu_table[docno][term] * idf(term)\n",
    "        c_dividend += w * d\n",
    "        c_divisor_w += w ** 2\n",
    "    for term in docu_table[docno]:\n",
    "        d = docu_table[docno][term] * idf(term)\n",
    "        c_divisor_d += d ** 2\n",
    "    return c_dividend / sqrt(c_divisor_d * c_divisor_w)\n",
    "\n",
    "def bm25Similarity(query, docno, query_counter, totaldl):\n",
    "    k1 = 1.2\n",
    "    k2 = 500\n",
    "    b = 0.75\n",
    "    N = len(docu_table)\n",
    "    D = sum(docu_table[docno].values())\n",
    "    avgdl = totaldl / len(docu_table)\n",
    "    res = 0\n",
    "    for term in query:\n",
    "        n = len(idx_table[term])\n",
    "        tf = idx_table[term][docno]\n",
    "        p1 = (k1 + 1) * tf / (tf + k1 * (1 - b + b * D / avgdl))\n",
    "        p2 = (k2 + 1) * query_counter[term] / (k2 + query_counter[term])\n",
    "        res += idf(term) * p1 * p2\n",
    "    return res\n",
    "\n",
    "def lmSimilarity(query, docno, query_counter, totaldl):\n",
    "    D = sum(docu_table[docno].values())\n",
    "    avgdl = totaldl / len(docu_table)\n",
    "    res = 0\n",
    "    for term in query:\n",
    "        tf = idx_table[term][docno]\n",
    "        tfC = sum(idx_table[term].values())\n",
    "        res += log(((tf + avgdl * tfC / totaldl) / (D + avgdl)), 10)\n",
    "    return res\n",
    "\n",
    "def relevanceRanking(query, totaldl):\n",
    "    result = Counter()\n",
    "    # find relevant doc containing at least one query term\n",
    "    relevant_doc = set()\n",
    "    for term in query:\n",
    "        for docno in idx_table[term]:\n",
    "            relevant_doc.add(docno)\n",
    "    # build query counter to calculate tf in query\n",
    "    query_counter = Counter()\n",
    "    for term in query:\n",
    "        query_counter[term] += 1\n",
    "    # calculate relevance\n",
    "    for docno in relevant_doc:\n",
    "        if retrieval_model == 'cosine':\n",
    "            result[docno] = cosineSimilarity(query, docno, query_counter)\n",
    "        elif retrieval_model == 'bm25':\n",
    "            result[docno] = bm25Similarity(query, docno, query_counter, totaldl)\n",
    "        elif retrieval_model == 'lm':\n",
    "            result[docno] = lmSimilarity(query, docno, query_counter, totaldl)\n",
    "    return result.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefixReplace(match):\n",
    "    prefix, stem = match.group(1), match.group(2)\n",
    "    temp = prefix + stem\n",
    "    if not stem in stop_words:\n",
    "        temp += ' ' + stem\n",
    "    return temp\n",
    "\n",
    "def hyphenReplace(match):\n",
    "    temp = match.group()\n",
    "    li = temp.split('-')\n",
    "    temp = temp.replace('-', '')\n",
    "    for item in li:\n",
    "        if not item in stop_words:\n",
    "            temp += ' ' + item\n",
    "    return temp\n",
    "\n",
    "def loadIndexTables():\n",
    "    f = open('single_term_idx_table.txt', 'r')\n",
    "    totaldl = 0\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if not parts[0] in idx_table:\n",
    "            idx_table[parts[0]] = Counter()\n",
    "        if not parts[1] in docu_table:\n",
    "            docu_table[parts[1]] = Counter()\n",
    "        # term, docno, term frequency\n",
    "        idx_table[parts[0]][parts[1]] = int(parts[2])\n",
    "        docu_table[parts[1]][parts[0]] = int(parts[2])\n",
    "        totaldl += int(parts[2])\n",
    "    f.close()\n",
    "    # calculate tf*idf and store in cluster table\n",
    "    for docno in docu_table:\n",
    "        weight_table[docno] = Counter()\n",
    "        for term in docu_table[docno]:\n",
    "            weight_table[docno][term] = docu_table[docno][term] * idf(term)\n",
    "    return totaldl\n",
    "\n",
    "def queryOutput(query_path, output_file, totaldl):\n",
    "    if query_path[0] == '/':\n",
    "        query_path = '.' + query_path\n",
    "    if query_path[-1] != '/':\n",
    "        query_path += '/'\n",
    "    \n",
    "    files = glob.glob(query_path+'*') # grab all the files under path\n",
    "    output_file = open(output_file, 'w') # open output file\n",
    "    output_file.write('Descritpion_ID,Top_20_Image_IDs\\n')\n",
    "    p_prefix = re.compile(r'\\b(a|an|ante|anti|auto|circum|co|com|con|contra|contro|de|dis|en|em|ex|extra|fore|hetero|homo|homeo|hyper|il|im|in|ir|inter|intra|intro|macro|micro|mid|mis|mono|non|omni|over|post|pre|pro|re|semi|sub|super|sym|syn|trans|tri|un|under|uni)-([a-z])+\\b', re.I)\n",
    "    p_hyphen = re.compile(r'\\b(\\w+-)+\\w+\\b')\n",
    "    get_num = re.compile(r'(\\d+)')\n",
    "    for file in files:\n",
    "        f = open(file, 'r')\n",
    "        docno = int(get_num.search(file).group(1))\n",
    "        output_file.write(str(docno)+\".txt,\")\n",
    "        query = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            line = line.lower()\n",
    "            # expand stem with hyphen prefix\n",
    "            line = p_prefix.sub(prefixReplace, line)\n",
    "            # expand hyphenated word\n",
    "            line = p_hyphen.sub(hyphenReplace, line)\n",
    "            line = line.replace(':', ' ')\n",
    "            line = nltk.word_tokenize(line)\n",
    "            query += [x for x in line if x in idx_table]\n",
    "        result = relevanceRanking(query, totaldl)\n",
    "        # print(result)\n",
    "        output_file.write(' '.join(x[0]+'.jpg' for x in result))\n",
    "        output_file.write('\\n')\n",
    "    output_file.close()\n",
    "\n",
    "totaldl = loadIndexTables()\n",
    "queryOutput('data/descriptions_test', retrieval_model+'submission.csv', totaldl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
